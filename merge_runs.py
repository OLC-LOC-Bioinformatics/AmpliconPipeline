#!/usr/bin/env python3

import click
from qiime2.plugins import feature_table
from bin.qiime2_pipeline import *

"""
This script is meant to merge separate MiSeq runs into a single workable analysis. It also supports filtering the merged
tables down to a select set of samples. Specifically, it will merge the rep_seqs and dada2 table artifacts produced by
ampliconpipeline.py, usually with the --filtering_flag.

Example scenario:
We have two runs containing multiple sample types (veal, beef, sprouts).
We only want to look at the sprout samples across the two runs, so we can first merge them, and then filter them
down with this script. The final analysis files will only contain the sprouts samples.

TODO: Allow for an unlimited number of tables/repseqs artifacts to be passed in and merged. This would be much more
useful than the mandatory 2 right now. Unfortunately Click does not easily support the equivalent of nargs='*' so I'm 
putting off doing this for now.
"""

logging.basicConfig(
    format='\033[92m \033[1m %(asctime)s \033[0m %(message)s ',
    level=logging.INFO,
    datefmt='%Y-%m-%d %H:%M:%S')


def merge_run_tables(table1_artifact_path, table2_artifact_path):
    """
    :param table1_artifact_path: str path to DADA2 table .qza file (first run)
    :param table2_artifact_path: str path to DADA2 table .qza file (second run)
    :return: Merged QIIME2 DADA2 table object
    """
    logging.info('Merging {} and {}...'.format(table1_artifact_path, table2_artifact_path))
    table1 = load_data_artifact(table1_artifact_path)
    table2 = load_data_artifact(table2_artifact_path)
    dada2_filtered_table = feature_table.actions.merge(tables=[table1, table2]).merged_table
    return dada2_filtered_table


def merge_run_repseqs(repseqs1_artifact_path, repseqs2_artifact_path):
    """
    :param repseqs1_artifact_path: str path to representative sequences .qza file (first run)
    :param repseqs2_artifact_path: str path to representative sequences .qza file (second run)
    :return: Merged QIIME2 representative sequences object
    """
    logging.info('Merging {} and {}...'.format(repseqs1_artifact_path, repseqs2_artifact_path))
    repseqs1 = load_data_artifact(repseqs1_artifact_path)
    repseqs2 = load_data_artifact(repseqs2_artifact_path)
    dada2_filtered_rep_seqs = feature_table.actions.merge_seqs(data=[repseqs1, repseqs2]).merged_data
    return dada2_filtered_rep_seqs


def filter_run_tables(sample_id_file, dada2_table):
    """
    This takes a list of sample IDs (must be present in your metadata for the merged runs) and then filters the
    DADA2 table down to only the requested samples. The sample_id_file should be a .tsv file with one column with the
    header '#SampleID' and Seq IDs for each row.

    :param sample_id_file: path to .tsv file containing desired IDs
    :param dada2_table: DADA2 table object
    :return: Filtered DADA2 table object
    """
    logging.info('Filtering table using {}...'.format(sample_id_file))
    samples = load_sample_metadata(sample_id_file)
    filtered_table = feature_table.actions.filter_samples(table=dada2_table, metadata=samples).filtered_table
    return filtered_table


def filter_run_repseqs(sample_id_file, dada2_rep_seqs):
    """
    Same as filter_run_tables, except operates with the rep_seqs object

    :param sample_id_file: path to .tsv file containing desired IDs
    :param dada2_rep_seqs: DADA2 representative sequences object
    :return: Filtered representative sequences object
    """
    logging.info('Filtering repseqs using {}...'.format(sample_id_file))
    samples = load_sample_metadata(sample_id_file)
    rep_seqs = feature_table.actions.filter_seqs(data=dada2_rep_seqs, metadata=samples, exclude_ids=True).filtered_data
    return rep_seqs


@click.command()
@click.option('-b', '--base_dir',
              type=click.Path(exists=False),
              required=True,
              help='Base directory for all output from QIIME2-MERGE Pipeline.')
@click.option('-m', '--sample_metadata_path',
              type=click.Path(exists=True),
              required=True,
              help='Path to QIIME2 tab-separated metadata file')
@click.option('-c', '--classifier_artifact_path',
              type=click.Path(exists=True),
              required=False,
              default='./classifiers/99_V3V4_Silva_naive_bayes_classifier.qza',
              help='Path to QIIME2 Classifier Artifact')
@click.option('-t1', '--table1_artifact_path',
              type=click.Path(exists=True),
              required=True,
              help='Path to first table artifact generated by DADA2 for merging')
@click.option('-t2', '--table2_artifact_path',
              type=click.Path(exists=True),
              required=True,
              help='Path to second table artifact generated by DADA2 for merging')
@click.option('-rs1', '--repseqs1_artifact_path',
              type=click.Path(exists=True),
              required=True,
              help='Path to first representative sequences artifact generated by DADA2 for merging')
@click.option('-rs2', '--repseqs2_artifact_path',
              type=click.Path(exists=True),
              required=True,
              help='Path to second representative sequences artifact generated by DADA2 for merging')
@click.option('-f', '--filtering_list',
              required=False,
              type=click.Path(exists=True),
              default=None,
              help='Path to a .tsv file containing sample IDs that you wish to keep for the analysis.'
                   'Each sample ID should be on a new row. The header for this .tsv must be #SampleID')
def run_merge_pipeline(base_dir, sample_metadata_path, classifier_artifact_path,
                       table1_artifact_path, table2_artifact_path, repseqs1_artifact_path, repseqs2_artifact_path,
                       filtering_list):
    """
    How this works:

    1. Loads and merges dada2 results from two previous analyses (requires rep-seqs-dada2 and table-dada2 for each run)

    2. Runs the full pipeline as usual with the merged run

    NOTE: A metadata .tsv file containing information for BOTH runs is required.

    Optionally, you may also provide a 'filtering list' which is a text file containing a sample ID on each new line
    which will only run the pipeline on the provided samples.
    """
    # Make sure base_dir exists
    if not os.path.isdir(base_dir):
        os.makedirs(base_dir)

    # Load metadata
    metadata_object = load_sample_metadata(sample_metadata_path)

    # Merge runs
    dada2_merged_table = merge_run_tables(table1_artifact_path, table2_artifact_path)
    dada2_merged_rep_seqs = merge_run_repseqs(repseqs1_artifact_path, repseqs2_artifact_path)

    # Filter runs
    if filtering_list is not None:
        dada2_merged_table = filter_run_tables(sample_id_file=filtering_list,
                                               dada2_table=dada2_merged_table)
        dada2_merged_rep_seqs = filter_run_repseqs(sample_id_file=filtering_list,
                                                   dada2_rep_seqs=dada2_merged_rep_seqs)

    # Continue pipeline as normal
    # Visualize dada2
    visualize_dada2(base_dir=base_dir,
                    dada2_filtered_table=dada2_merged_table,
                    dada2_filtered_rep_seqs=dada2_merged_rep_seqs,
                    metadata_object=metadata_object)

    # Mask and alignment
    (seq_mask, seq_alignment) = seq_alignment_mask(base_dir=base_dir,
                                                   dada2_filtered_rep_seqs=dada2_merged_rep_seqs)

    # Phylogenetic tree
    (phylo_unrooted_tree, phylo_rooted_tree) = phylo_tree(base_dir=base_dir, seq_mask=seq_mask)

    # Export tree
    export_newick(base_dir=base_dir, tree=phylo_rooted_tree)

    # Load classifier
    classifier = load_artifact(artifact_path=classifier_artifact_path)

    # Produce rarefaction visualization
    alpha_rarefaction_visualization(base_dir=base_dir,
                                    dada2_filtered_table=dada2_merged_table)

    # Run taxonomic analysis
    taxonomy_analysis = classify_taxonomy(base_dir=base_dir,
                                          dada2_filtered_rep_seqs=dada2_merged_rep_seqs,
                                          classifier=classifier)

    # Visualize taxonomy
    visualize_taxonomy(base_dir=base_dir,
                       metadata_object=metadata_object,
                       taxonomy_analysis=taxonomy_analysis,
                       dada2_filtered_table=dada2_merged_table)

    # Alpha and beta diversity
    run_diversity_metrics(base_dir=base_dir,
                          dada2_filtered_table=dada2_merged_table,
                          phylo_rooted_tree=phylo_rooted_tree,
                          metadata_object=metadata_object)


if __name__ == '__main__':
    run_merge_pipeline()
